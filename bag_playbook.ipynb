{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the librairies and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [('VAR', 'Responder'), ('AND', '&'), ('LPAREN', '('), ('VAR', 'impacket'), ('OR', '|'), ('VAR', 'Metasploit'), ('RPAREN', ')')]\n",
      "AST: Responder&impacket|Metasploit\n",
      "&\n",
      "Responder\n",
      "|\n",
      "impacket\n",
      "Metasploit\n",
      "Compiled Expression: (Responder & (impacket | Metasploit))\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from BAG_Code_tw520.BayesianAttackGraph import parse_dot\n",
    "from BAG_Code_tw520.createANDtable import create_AND_table\n",
    "from BAG_Code_tw520.createORtable import create_OR_table\n",
    "from BAG_Code_tw520.Tools_tree import tokenizer, Parser, build_tools_tree\n",
    "import BAG_Code_tw520.Loopy as Loopy\n",
    "\n",
    "from pgmpy.inference.ExactInference import BeliefPropagation\n",
    "from pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the simulation use the following to put the graph in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the simulation\n",
    "simulation = \"HightLevel\"\n",
    "\n",
    "# Constante for probability one\n",
    "ONE = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dot(BAG, nodes, evidences, path, basename, display_kts=False, calculate_probabilities=False):\n",
    "    evidences = {str(k): 1 for k in evidences}\n",
    "    dot = 'digraph G {\\n'\n",
    "    regex = r\"\\d+:RULE \\d+ \\((.*?)\\):\\d+\\.\\d+\"\n",
    "    print(BAG)\n",
    "    # Exact inference\n",
    "    if calculate_probabilities ==1:\n",
    "        nodes_wo_evidences = [n for n in nodes.keys() if n not in evidences.keys()]\n",
    "        nodes_1 = nodes_wo_evidences[:len(nodes_wo_evidences)//3]\n",
    "        nodes_2 = nodes_wo_evidences[len(nodes_wo_evidences)//3:(len(nodes_wo_evidences)*2)//3]\n",
    "        nodes_3 = nodes_wo_evidences[(len(nodes_wo_evidences)*2)//3:]\n",
    "        prop = BeliefPropagation(BAG)\n",
    "        total_prob1 = prop.query(nodes_1, evidence=evidences)\n",
    "        total_prob2 = prop.query(nodes_2, evidence=evidences)\n",
    "        total_prob3 = prop.query(nodes_3, evidence=evidences)\n",
    "    # Loopy propagation\n",
    "    if calculate_probabilities == 2:\n",
    "        marginals = Loopy.RunLBP(Loopy.CreateFactorGraph(Loopy.ToMarkov(BAG)), evidences)\n",
    "        marginals = list(marginals.values())[0]\n",
    "    # Return to general case\n",
    "    honeynodes = [str(n) for n in range(23,52)]\n",
    "\n",
    "    def node_to_dot(node):\n",
    "        if node not in evidences.keys() and calculate_probabilities == 1:\n",
    "            # prob = prop.query([node], evidence=evidences).values[1]\n",
    "            if node in nodes_1:\n",
    "                prob = total_prob1.marginalize([n for n in nodes_1 if n != node], inplace=False).values[1]\n",
    "            elif node in nodes_2:\n",
    "                prob = total_prob2.marginalize([n for n in nodes_2 if n != node], inplace=False).values[1]\n",
    "            elif node in nodes_3:\n",
    "                prob = total_prob3.marginalize([n for n in nodes_3 if n != node], inplace=False).values[1]\n",
    "        elif calculate_probabilities == 2:\n",
    "            prob = marginals[node][1]\n",
    "        else:\n",
    "            prob = 1\n",
    "        probH = int(prob * 255)\n",
    "        color = '#' + format(probH, '02X') +''+ format(255-probH, '02X') + '00'\n",
    "        CVE = nodes[node]['CVE']\n",
    "        LABEL = nodes[node]['label']\n",
    "        number = LABEL.split(\":\")[0]\n",
    "        color = 'blue' if number in honeynodes else color\n",
    "        prob = \"{:.4f}\".format(prob)\n",
    "        shape = nodes[node]['shape']\n",
    "        if CVE != 'null':\n",
    "            return f'  {node} [label=\\\"{node} ({number})\\\\n{CVE}\\\\n{prob}\\\", color=\\\"{color}\\\", penwidth=3, shape=\\\"{shape}\\\"];\\n'\n",
    "        else:\n",
    "            correspondance = re.search(regex, LABEL)\n",
    "            if correspondance:\n",
    "                return f'  {node} [label=\\\"{node} ({number})\\\\n{correspondance.group(1)}\\\\n{prob}\\\", color=\\\"{color}\\\", penwidth=3, shape=\\\"{shape}\\\"];\\n'\n",
    "            else:\n",
    "                return f'  {node} [label=\"{node} ({number})\\\\n{LABEL}\\\\n{prob}\", color=\"{color}\", penwidth=3, shape=\"{shape}\"];\\n'\n",
    "            \n",
    "    for node in nodes.keys():\n",
    "        dot += node_to_dot(node)\n",
    "    for edge in BAG.edges():\n",
    "        if display_kts or edge[0] in nodes.keys():\n",
    "            dot += f'  \\\"{edge[0]}\\\" -> \\\"{edge[1]}\\\";\\n'\n",
    "    dot += '}'\n",
    "    with open(path / (basename + evidences_to_string(evidences) + \".dot\"), 'w') as f:\n",
    "        f.write(dot)\n",
    "\n",
    "def kts_layer(BAG, ONE, nodes):    \n",
    "    # The skills layer:\n",
    "    cpd_Lskills = TabularCPD('Lskills', 2, [[0.1], [0.9]])\n",
    "    cpd_Hskills = TabularCPD('Hskills', 2, [[0.9], [0.1]])\n",
    "    \n",
    "    # The knowledge layer:\n",
    "    cpd_knowledge = [TabularCPD(knowledge, 2, [[0.5], [0.5]]) for knowledge in ['Known vulnerabilities', 'CQCM', 'No credentials', 'MITM', 'Permissions move', 'Privilege escalation', 'Lateral move', 'ADCS']]\n",
    "\n",
    "    # Import all the dependencies\n",
    "    cpt_l4 = create_AND_table([ONE, ONE, ONE, ONE])\n",
    "    with open('./Threat_Inteligence/CVE_knowledge_tooling_skills.csv', mode='r') as ktsfile:\n",
    "        reader = csv.DictReader(ktsfile)\n",
    "        kts_dict = {}\n",
    "        for row in reader:\n",
    "            cve = row['Vulnerability']\n",
    "            tmp = {'tool': row['tool'], 'skills': row['skills'], 'Type': row['Type']}\n",
    "            kts_dict[cve] = tmp\n",
    "    for node in nodes.items():\n",
    "            id = node[0]\n",
    "            node = node[1]\n",
    "            if node['CVE'] != \"null\":\n",
    "                row = kts_dict[node['CVE']]\n",
    "                build_tools_tree(BAG, Parser(tokenizer(row['tool'])).parse(), id, ONE)\n",
    "                BAG.add_edge(row['skills'] + 'skills', id)\n",
    "                build_tools_tree(BAG, Parser(tokenizer(row['Type'])).parse(), id, ONE)\n",
    "                parents = BAG.get_parents(id)\n",
    "                BAG.remove_cpds(id)\n",
    "                BAG.add_cpds(TabularCPD(id, 2, cpt_l4.T, parents, evidence_card=2*np.ones(len(parents))))\n",
    "    # We add all the necessary CPDs to the BAG\n",
    "    for cpd in [cpd_Lskills, cpd_Hskills] + cpd_knowledge:\n",
    "        if BAG.__contains__(cpd.variable):\n",
    "            BAG.add_cpds(cpd)\n",
    "\n",
    "def rmv_node(BAG, node, edges):\n",
    "    edge = [(u,node) for u in BAG.get_parents(node)]\n",
    "    BAG.remove_edges_from(edge)\n",
    "    BAG.add_cpds(TabularCPD(node, 2, create_AND_table([0]).T))\n",
    "\n",
    "def evidences_to_string(evidences):\n",
    "    return ''.join([f'_{k}' for k, v in evidences.items()])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the folder containing the tree\n",
    "path = Path.cwd() / (\"Personnal_simulations/output_\" + simulation + \"/strongly_connected_components/\")\n",
    "file_name = \"ag-nocycles.dot\"\n",
    "path_to_dot = path / file_name\n",
    "basename = \"classic\"\n",
    "\n",
    "# We all read from the file, adding probabilities in the same time\n",
    "BAG, edges, nodes = parse_dot(open(path_to_dot, 'r').read(), ONE)\n",
    "\n",
    "# This is the reference BAG, before the attacker has compromised any node\n",
    "BAG_ref = BAG.copy()\n",
    "prop0 = BeliefPropagation(BAG_ref)\n",
    "\n",
    "# We create a dictionary to get the node number from the label\n",
    "inverted_nodes = {int(v['label'].split(':')[0]): k for k, v in nodes.items()}\n",
    "kts_layer(BAG, ONE, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dot(BAG_ref, nodes, [], path, \"reference\", display_kts=False, calculate_probabilities=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 39 nodes and 81 edges\n"
     ]
    }
   ],
   "source": [
    "# rmv_node(BAG, 22, edges)\n",
    "evidence = []\n",
    "to_dot(BAG, nodes, evidence, path, basename, display_kts=False, calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 39 nodes and 81 edges\n",
      "BayesianNetwork with 39 nodes and 81 edges\n"
     ]
    }
   ],
   "source": [
    "evidences = [ [13, 20], [13, 3, 20]]\n",
    "for evidence in evidences:\n",
    "    to_dot(BAG, nodes, evidence, path, basename, display_kts=False, calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "| Impacket    |   phi(Impacket) |\n",
      "+=============+=================+\n",
      "| Impacket(0) |          0.0014 |\n",
      "+-------------+-----------------+\n",
      "| Impacket(1) |          0.9986 |\n",
      "+-------------+-----------------+\n",
      "+-------------+-----------------+\n",
      "| Impacket    |   phi(Impacket) |\n",
      "+=============+=================+\n",
      "| Impacket(0) |          0.0002 |\n",
      "+-------------+-----------------+\n",
      "| Impacket(1) |          0.9998 |\n",
      "+-------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "tab = BeliefPropagation(BAG).query(['Impacket'], evidence={str(13): 1, str(20): 1})\n",
    "print(tab)\n",
    "tab = BeliefPropagation(BAG).query(['Impacket'], evidence={str(13): 1, str(22): 1})\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "| A    | A(0) | A(1) |\n",
      "+------+------+------+\n",
      "| B(0) | 0.8  | 0.3  |\n",
      "+------+------+------+\n",
      "| B(1) | 0.2  | 0.7  |\n",
      "+------+------+------+\n",
      "+------+----------+\n",
      "| A    |   phi(A) |\n",
      "+======+==========+\n",
      "| A(0) |   0.3404 |\n",
      "+------+----------+\n",
      "| A(1) |   0.6596 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "bayesian_model = BayesianNetwork([('A', 'B')])\n",
    "\n",
    "cpt_a =[[0.5], [0.5]]\n",
    "cpd_a = TabularCPD('A', 2, cpt_a)\n",
    "cpd_b = TabularCPD('B', 2, [[0.8, 0.3], [0.2,0.7]], ['A'], evidence_card=[2])\n",
    "cpd_virtual = TabularCPD('B', 2, [[0.2],[0.8]])\n",
    "\n",
    "bayesian_model.add_cpds(cpd_a, cpd_b)\n",
    "belief_propagation = BeliefPropagation(bayesian_model)\n",
    "print(bayesian_model.get_cpds('B'))\n",
    "print(belief_propagation.query(variables=['A'], virtual_evidence={cpd_virtual}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

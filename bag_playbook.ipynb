{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the librairies and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [('VAR', 'Responder'), ('AND', '&'), ('LPAREN', '('), ('VAR', 'impacket'), ('OR', '|'), ('VAR', 'Metasploit'), ('RPAREN', ')')]\n",
      "AST: Responder&impacket|Metasploit\n",
      "&\n",
      "Responder\n",
      "|\n",
      "impacket\n",
      "Metasploit\n",
      "Compiled Expression: (Responder & (impacket | Metasploit))\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from BAG_Code_tw520.BayesianAttackGraph import parse_dot\n",
    "from BAG_Code_tw520.createANDtable import create_AND_table\n",
    "from BAG_Code_tw520.createORtable import create_OR_table\n",
    "from BAG_Code_tw520.Tools_tree import tokenizer, Parser, build_tools_tree\n",
    "import BAG_Code_tw520.Loopy as Loopy\n",
    "\n",
    "from pgmpy.inference.ExactInference import BeliefPropagation\n",
    "from pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the simulation use the following to put the graph in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the simulation\n",
    "simulation = \"HightLevel\"\n",
    "\n",
    "# Constante for probability one\n",
    "ONE = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dot(BAG, nodes, evidences, display_kts=False, calculate_probabilities=False):\n",
    "    dot = 'digraph G {\\n'\n",
    "    regex = r\"\\d+:RULE \\d+ \\((.*?)\\):\\d+\\.\\d+\"\n",
    "    print(BAG)\n",
    "    # Exact inference\n",
    "    if calculate_probabilities ==1:\n",
    "        nodes_wo_evidences = [n for n in nodes.keys() if n not in evidences.keys()]\n",
    "        nodes_1 = nodes_wo_evidences[:len(nodes_wo_evidences)//3]\n",
    "        nodes_2 = nodes_wo_evidences[len(nodes_wo_evidences)//3:(len(nodes_wo_evidences)*2)//3]\n",
    "        nodes_3 = nodes_wo_evidences[(len(nodes_wo_evidences)*2)//3:]\n",
    "        prop = BeliefPropagation(BAG)\n",
    "        total_prob1 = prop.query(nodes_1, evidence=evidences)\n",
    "        total_prob2 = prop.query(nodes_2, evidence=evidences)\n",
    "        total_prob3 = prop.query(nodes_3, evidence=evidences)\n",
    "    # Loopy propagation\n",
    "    if calculate_probabilities == 2:\n",
    "        marginals = Loopy.RunLBP(Loopy.CreateFactorGraph(Loopy.ToMarkov(BAG)), evidences)\n",
    "        marginals = list(marginals.values())[0]\n",
    "    # Return to general case\n",
    "    honeynodes = [str(n) for n in range(26,52)]\n",
    "\n",
    "    def node_to_dot(node):\n",
    "        if node not in evidences.keys() and calculate_probabilities == 1:\n",
    "            # prob = prop.query([node], evidence=evidences).values[1]\n",
    "            if node in nodes_1:\n",
    "                prob = total_prob1.marginalize([n for n in nodes_1 if n != node], inplace=False).values[1]\n",
    "            elif node in nodes_2:\n",
    "                prob = total_prob2.marginalize([n for n in nodes_2 if n != node], inplace=False).values[1]\n",
    "            elif node in nodes_3:\n",
    "                prob = total_prob3.marginalize([n for n in nodes_3 if n != node], inplace=False).values[1]\n",
    "        elif node not in evidences.keys() and calculate_probabilities == 2:\n",
    "            prob = marginals[node][1]\n",
    "        else:\n",
    "            prob = 1\n",
    "        probH = int(prob * 255)\n",
    "        color = '#' + format(probH, '02X') +''+ format(255-probH, '02X') + '00'\n",
    "        CVE = nodes[node]['CVE']\n",
    "        LABEL = nodes[node]['label']\n",
    "        number = LABEL.split(\":\")[0]\n",
    "        color = 'blue' if number in honeynodes else color\n",
    "        prob = \"{:.3f}\".format(prob)\n",
    "        shape = nodes[node]['shape']\n",
    "        if CVE != 'null':\n",
    "            return f'  {node} [label=\\\"{node} ({number})\\\\n{CVE}\\\\n{prob}\\\", color=\\\"{color}\\\", penwidth=3, shape=\\\"{shape}\\\"];\\n'\n",
    "        else:\n",
    "            correspondance = re.search(regex, LABEL)\n",
    "            if correspondance:\n",
    "                return f'  {node} [label=\\\"{node} ({number})\\\\n{correspondance.group(1)}\\\\n{prob}\\\", color=\\\"{color}\\\", penwidth=3, shape=\\\"{shape}\\\"];\\n'\n",
    "            else:\n",
    "                return f'  {node} [label=\"{node} ({number})\\\\n{LABEL}\\\\n{prob}\", color=\"{color}\", penwidth=3, shape=\"{shape}\"];\\n'\n",
    "            \n",
    "    for node in nodes.keys():\n",
    "        dot += node_to_dot(node)\n",
    "    for edge in BAG.edges():\n",
    "        if display_kts or edge[0] in nodes.keys():\n",
    "            dot += f'  \\\"{edge[0]}\\\" -> \\\"{edge[1]}\\\";\\n'\n",
    "    dot += '}'\n",
    "    return dot\n",
    "\n",
    "def kts_layer(BAG, ONE, nodes):    \n",
    "    # The skills layer:\n",
    "    cpd_Lskills = TabularCPD('Lskills', 2, [[0.1], [0.9]])\n",
    "    cpd_Hskills = TabularCPD('Hskills', 2, [[0.9], [0.1]])\n",
    "    # cpd_Lskills = TabularCPD('Lskills', 2, [[0.5], [0.5]])\n",
    "\n",
    "    \n",
    "    # The knowledge layer:\n",
    "    cpd_knowledge = [TabularCPD(knowledge, 2, [[0.5], [0.5]]) for knowledge in ['Known vulnerabilities', 'CQCM', 'No credentials', 'MITM', 'Permissions move', 'Privilege escalation', 'Lateral move', 'ADCS']]\n",
    "\n",
    "    # Import all the dependencies\n",
    "    cpt_l4 = create_AND_table([ONE, ONE, ONE, ONE])\n",
    "    with open('./Threat_Inteligence/CVE_knowledge_tooling_skills.csv', mode='r') as ktsfile:\n",
    "        reader = csv.DictReader(ktsfile)\n",
    "        kts_dict = {}\n",
    "        for row in reader:\n",
    "            cve = row['Vulnerability']\n",
    "            tmp = {'tool': row['tool'], 'skills': row['skills'], 'Type': row['Type']}\n",
    "            kts_dict[cve] = tmp\n",
    "    for node in nodes.items():\n",
    "            id = node[0]\n",
    "            node = node[1]\n",
    "            if node['CVE'] != \"null\":\n",
    "                row = kts_dict[node['CVE']]\n",
    "                build_tools_tree(BAG, Parser(tokenizer(row['tool'])).parse(), id, ONE)\n",
    "                BAG.add_edge(row['skills'] + 'skills', id)\n",
    "                build_tools_tree(BAG, Parser(tokenizer(row['Type'])).parse(), id, ONE)\n",
    "                parents = BAG.get_parents(id)\n",
    "                BAG.add_cpds(TabularCPD(id, 2, cpt_l4.T, parents, evidence_card=2*np.ones(len(parents))))\n",
    "    # We add all the necessary CPDs to the BAG\n",
    "    for cpd in [cpd_Lskills, cpd_Hskills] + cpd_knowledge:\n",
    "        if BAG.__contains__(cpd.variable):\n",
    "            BAG.add_cpds(cpd)\n",
    "\n",
    "def rmv_node(BAG, node, edges):\n",
    "    edge = [(u,node) for u in BAG.get_parents(node)]\n",
    "    BAG.remove_edges_from(edge)\n",
    "    BAG.add_cpds(TabularCPD(node, 2, create_AND_table([0]).T))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the folder containing the tree\n",
    "path = Path.cwd() / (\"Personnal_simulations/output_\" + simulation + \"/strongly_connected_components/\")\n",
    "file_name = \"ag-nocycles.dot\"\n",
    "path_to_dot = path / file_name\n",
    "basename = \"loopy_\"\n",
    "\n",
    "# We all read from the file, adding probabilities in the same time\n",
    "BAG, edges, nodes = parse_dot(open(path_to_dot, 'r').read(), ONE)\n",
    "\n",
    "# This is the reference BAG, before the attacker has compromised any node\n",
    "BAG_ref = BAG.copy()\n",
    "prop0 = BeliefPropagation(BAG_ref)\n",
    "\n",
    "# We create a dictionary to get the node number from the label\n",
    "inverted_nodes = {int(v['label'].split(':')[0]): k for k, v in nodes.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAG.remove_edges_from([(12,11 ) , (11,10), (10,9), (9,8)])\n",
    "# BAG.remove_nodes_from([11,10,9])\n",
    "# nodes = {k: v for k, v in nodes.items() if k not in [11,10,9]}\n",
    "# BAG.add_edges_from([(12,8)])\n",
    "# BAG.add_cpds(TabularCPD(8, 2, create_AND_table([ONE]).T, [12], evidence_card=2*np.ones(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pgmpy:Replacing existing CPD for 2\n",
      "WARNING:pgmpy:Replacing existing CPD for 4\n",
      "WARNING:pgmpy:Replacing existing CPD for 6\n",
      "WARNING:pgmpy:Replacing existing CPD for 8\n",
      "WARNING:pgmpy:Replacing existing CPD for 10\n",
      "WARNING:pgmpy:Replacing existing CPD for 12\n",
      "WARNING:pgmpy:Replacing existing CPD for 14\n",
      "WARNING:pgmpy:Replacing existing CPD for 16\n",
      "WARNING:pgmpy:Replacing existing CPD for 18\n",
      "WARNING:pgmpy:Replacing existing CPD for 20\n",
      "WARNING:pgmpy:Replacing existing CPD for 22\n",
      "WARNING:pgmpy:Replacing existing CPD for 23\n",
      "WARNING:pgmpy:Replacing existing CPD for 24\n",
      "WARNING:pgmpy:Replacing existing CPD for 26\n",
      "WARNING:pgmpy:Replacing existing CPD for 27\n"
     ]
    }
   ],
   "source": [
    "kts_layer(BAG, ONE, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmv_node(BAG, 22, edges)\n",
    "# BAG.get_parents(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 45 nodes and 85 edges\n",
      "marginals {VarDict(num_states=array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2], dtype=int64), _hash=3099039872000000000, variable_names=('11', '10', '16', 'Hashcat|John', 'Lskills', 'CrackingHash', 'Responder&Impacket', 'Hskills', 'LateralMove', '9', '8', 'Cme', '7', '6', '23', '5', '12', '4', '27', 'Rubeus', 'Kerberos', '15', '14', '26', 'Lsassy|Impacket', '13', '22', 'Impacket', 'PrivilegeEscalation', '3', '2', '28', 'Impacket|Rubeus', '1', '21', '24', '20', '25', '19', '18', '17', 'Lsassy', 'Responder', 'Hashcat', 'John')): {'1': Array([0.9574864 , 0.04251368], dtype=float32), '10': Array([0.69155765, 0.30844238], dtype=float32), '11': Array([1.4330055e-05, 9.9998569e-01], dtype=float32), '12': Array([0.966795  , 0.03320495], dtype=float32), '13': Array([0.96537083, 0.03462919], dtype=float32), '14': Array([0.99099594, 0.00900407], dtype=float32), '15': Array([0.9513259 , 0.04867414], dtype=float32), '16': Array([0.97650343, 0.02349654], dtype=float32), '17': Array([0.62238425, 0.37761575], dtype=float32), '18': Array([0.97905374, 0.02094628], dtype=float32), '19': Array([0.7624848 , 0.23751521], dtype=float32), '2': Array([0.98704535, 0.01295465], dtype=float32), '20': Array([0.90279025, 0.09720978], dtype=float32), '21': Array([0.76402867, 0.23597124], dtype=float32), '22': Array([0.966795  , 0.03320495], dtype=float32), '23': Array([0.95222294, 0.04777701], dtype=float32), '24': Array([0.966795  , 0.03320494], dtype=float32), '25': Array([0.96537083, 0.03462918], dtype=float32), '26': Array([0.99099594, 0.00900407], dtype=float32), '27': Array([0.9247036 , 0.07529636], dtype=float32), '28': Array([0.77076316, 0.22923681], dtype=float32), '3': Array([0.879573  , 0.12042702], dtype=float32), '4': Array([0.9247036 , 0.07529636], dtype=float32), '5': Array([0.8321762 , 0.16782378], dtype=float32), '6': Array([0.95222294, 0.04777701], dtype=float32), '7': Array([0.9017058 , 0.09829414], dtype=float32), '8': Array([0.93436986, 0.06563017], dtype=float32), '9': Array([0.74865896, 0.25134102], dtype=float32), 'Cme': Array([0.5       , 0.49999994], dtype=float32), 'CrackingHash': Array([0.49999997, 0.5       ], dtype=float32), 'Hashcat': Array([0.5       , 0.49999997], dtype=float32), 'Hashcat|John': Array([0.25673884, 0.7432611 ], dtype=float32), 'Hskills': Array([0.8936483 , 0.10635167], dtype=float32), 'Impacket': Array([0.49999994, 0.5       ], dtype=float32), 'Impacket|Rubeus': Array([0.25673878, 0.7432612 ], dtype=float32), 'John': Array([0.5       , 0.49999997], dtype=float32), 'Kerberos': Array([0.4999999 , 0.50000006], dtype=float32), 'LateralMove': Array([0.5       , 0.49999997], dtype=float32), 'Lsassy': Array([0.5, 0.5], dtype=float32), 'Lsassy|Impacket': Array([0.25673884, 0.7432612 ], dtype=float32), 'Lskills': Array([0.10635165, 0.8936484 ], dtype=float32), 'PrivilegeEscalation': Array([0.4999999, 0.5000001], dtype=float32), 'Responder': Array([0.5       , 0.49999997], dtype=float32), 'Responder&Impacket': Array([0.7390553 , 0.26094466], dtype=float32), 'Rubeus': Array([0.49999997, 0.50000006], dtype=float32)}}\n",
      "BayesianNetwork with 28 nodes and 32 edges\n"
     ]
    }
   ],
   "source": [
    "evidence = {\"15\":1, \"24\":1}\n",
    "with open(path / (basename + \"15_24\" \".dot\"), 'w') as f:\n",
    "    f.write(to_dot(BAG, nodes, evidence, display_kts=True, calculate_probabilities=2))\n",
    "with open(path / (\"BAG_ref\" + \".dot\"), 'w') as f:\n",
    "    f.write(to_dot(BAG_ref, nodes, evidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 45 nodes and 81 edges\n"
     ]
    }
   ],
   "source": [
    "evidence = {15:1}\n",
    "with open(path / (\"output_\" + str(15) + \".dot\"), 'w') as f:\n",
    "    f.write(to_dot(BAG, nodes, evidence, display_kts=False, calculate_probabilities=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 45 nodes and 85 edges\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Node 15 not in not in graph",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m evidence \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m15\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m24\u001b[39m:\u001b[38;5;241m1\u001b[39m}\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path \u001b[38;5;241m/\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m15_24\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.dot\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mto_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBAG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_kts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_probabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m, in \u001b[0;36mto_dot\u001b[1;34m(BAG, nodes, evidences, display_kts, calculate_probabilities)\u001b[0m\n\u001b[0;32m     10\u001b[0m nodes_3 \u001b[38;5;241m=\u001b[39m nodes_wo_evidences[(\u001b[38;5;28mlen\u001b[39m(nodes_wo_evidences)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m     11\u001b[0m prop \u001b[38;5;241m=\u001b[39m BeliefPropagation(BAG)\n\u001b[1;32m---> 12\u001b[0m total_prob1 \u001b[38;5;241m=\u001b[39m \u001b[43mprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevidences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m total_prob2 \u001b[38;5;241m=\u001b[39m prop\u001b[38;5;241m.\u001b[39mquery(nodes_2, evidence\u001b[38;5;241m=\u001b[39mevidences)\n\u001b[0;32m     14\u001b[0m total_prob3 \u001b[38;5;241m=\u001b[39m prop\u001b[38;5;241m.\u001b[39mquery(nodes_3, evidence\u001b[38;5;241m=\u001b[39mevidences)\n",
      "File \u001b[1;32mc:\\Users\\docuser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pgmpy\\inference\\ExactInference.py:1118\u001b[0m, in \u001b[0;36mBeliefPropagation.query\u001b[1;34m(self, variables, evidence, virtual_evidence, joint, show_progress)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;66;03m# Step 3: Do network pruning.\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, BayesianNetwork):\n\u001b[1;32m-> 1118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, evidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prune_bayesian_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_structures()\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;66;03m# Step 4: Run inference.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\docuser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pgmpy\\inference\\base.py:153\u001b[0m, in \u001b[0;36mInference._prune_bayesian_model\u001b[1;34m(self, variables, evidence)\u001b[0m\n\u001b[0;32m    149\u001b[0m variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnodes()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(variables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(variables)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Step 1: Remove all the variables that are d-separated from `variables` when conditioned\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m#         on `evidence`\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m d_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_trail_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_latents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m d_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;241m*\u001b[39md_connected\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39munion(evidence\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    157\u001b[0m bn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msubgraph(d_connected)\n",
      "File \u001b[1;32mc:\\Users\\docuser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pgmpy\\base\\DAG.py:719\u001b[0m, in \u001b[0;36mDAG.active_trail_nodes\u001b[1;34m(self, variables, observed, include_latents)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    718\u001b[0m     observed_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 719\u001b[0m ancestors_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ancestors_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;66;03m# Direction of flow of information\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# up ->  from parent to child\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;66;03m# down -> from child to parent\u001b[39;00m\n\u001b[0;32m    725\u001b[0m active_trails \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\docuser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pgmpy\\base\\DAG.py:781\u001b[0m, in \u001b[0;36mDAG._get_ancestors_of\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[1;32m--> 781\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in not in graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    783\u001b[0m ancestors_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    784\u001b[0m nodes_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(nodes)\n",
      "\u001b[1;31mValueError\u001b[0m: Node 15 not in not in graph"
     ]
    }
   ],
   "source": [
    "evidence = {15:1, 24:1}\n",
    "with open(path / (\"output_\" + \"15_24\" + \".dot\"), 'w') as f:\n",
    "    f.write(to_dot(BAG, nodes, evidence, display_kts=False, calculate_probabilities=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 45 nodes and 85 edges\n"
     ]
    }
   ],
   "source": [
    "evidence = {15:1, 5:1}\n",
    "with open(path / (\"output_\" + \"15_5\" + \".dot\"), 'w') as f:\n",
    "    f.write(to_dot(BAG, nodes, evidence, display_kts=False, calculate_probabilities=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When the attacker become dcsync and we want to recalculate for domain admin\n",
    "src_node = [7, 10]\n",
    "dst_node = [ 14, 16, 12, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "| Hskills    |   phi(Hskills) |\n",
      "+============+================+\n",
      "| Hskills(0) |         0.0009 |\n",
      "+------------+----------------+\n",
      "| Hskills(1) |         0.9991 |\n",
      "+------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "tab = BeliefPropagation(BAG).query(['Hskills'], evidence=evidence)\n",
    "print(tab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

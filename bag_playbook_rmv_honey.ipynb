{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the librairies and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from BAG_Code_tw520.BayesianAttackGraph import parse_dot\n",
    "from BAG_Code_tw520.createANDtable import create_AND_table\n",
    "from BAG_Code_tw520.createORtable import create_OR_table\n",
    "from BAG_Code_tw520.Tools_tree import tokenizer, Parser\n",
    "import BAG_Code_tw520.Loopy as Loopy\n",
    "\n",
    "from pgmpy.inference.ExactInference import BeliefPropagation\n",
    "from pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the simulation use the following to put the graph in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the simulation\n",
    "simulation = \"HighLevel_no_HP\"\n",
    "\n",
    "# Constante for probability one\n",
    "ONE = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tools_tree(BAG, ast, id, ONE, kts_base_score):\n",
    "    if ast.type == 'AND':\n",
    "        prob = 1\n",
    "        for child in ast.children:\n",
    "            prob = prob * build_tools_tree(BAG, child, ast.__repr__(), ONE, kts_base_score)\n",
    "        return prob\n",
    "    elif ast.type == 'OR':\n",
    "        prod = 1        \n",
    "        for child in ast.children:\n",
    "            prod = prod * (1 - build_tools_tree(BAG, child, ast.__repr__(), ONE, kts_base_score))\n",
    "        return 1 - prod\n",
    "    else:\n",
    "        return kts_base_score[ast.__repr__()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dot(BAG, nodes, evidences, path, basename, display_kts=False, calculate_probabilities=False):\n",
    "    nodes_BAG = BAG.nodes()\n",
    "    evidences = {str(k): 1 for k in evidences}\n",
    "    dot = 'digraph G {\\nranksep=0.2;\\n'\n",
    "    regex_rule = r\"\\d+:RULE \\d+ \\((.*?)\\):\\d+\\.\\d+\"\n",
    "    regex_state = r\"\\d+:(.*?):\\d+\"\n",
    "    print(BAG)\n",
    "    # Exact inference\n",
    "    if calculate_probabilities ==1:\n",
    "        nodes_wo_evidences = [n for n in nodes_BAG.keys() if n not in evidences.keys()]\n",
    "        nodes_1 = nodes_wo_evidences[:len(nodes_wo_evidences)//3]\n",
    "        nodes_2 = nodes_wo_evidences[len(nodes_wo_evidences)//3:(len(nodes_wo_evidences)*2)//3]\n",
    "        nodes_3 = nodes_wo_evidences[(len(nodes_wo_evidences)*2)//3:]\n",
    "        prop = BeliefPropagation(BAG)\n",
    "        total_prob1 = prop.query(nodes_1, evidence=evidences)\n",
    "        total_prob2 = prop.query(nodes_2, evidence=evidences)\n",
    "        total_prob3 = prop.query(nodes_3, evidence=evidences)\n",
    "    # Loopy propagation\n",
    "    if calculate_probabilities == 2:\n",
    "        marginals = Loopy.RunLBP(Loopy.CreateFactorGraph(Loopy.ToMarkov(BAG)), evidences)\n",
    "        marginals = list(marginals.values())[0]\n",
    "    # Return to general case\n",
    "    honeynodes = [str(n) for n in range(15,52)]\n",
    "    dynamic_nodes = [str(n) for n in [20, 21,26]]\n",
    "\n",
    "    def node_to_dot(node):\n",
    "        prob = 1\n",
    "        if node not in evidences.keys() and calculate_probabilities == 1:\n",
    "            # prob = prop.query([node], evidence=evidences).values[1]\n",
    "            if node in nodes_1:\n",
    "                prob = total_prob1.marginalize([n for n in nodes_1 if n != node], inplace=False).values[1]\n",
    "            elif node in nodes_2:\n",
    "                prob = total_prob2.marginalize([n for n in nodes_2 if n != node], inplace=False).values[1]\n",
    "            elif node in nodes_3:\n",
    "                prob = total_prob3.marginalize([n for n in nodes_3 if n != node], inplace=False).values[1]\n",
    "        elif calculate_probabilities == 2:\n",
    "            prob = marginals[node][1]\n",
    "        else:\n",
    "            prob = 1\n",
    "        probH = int(prob * 255)\n",
    "        color = '#' + format(probH, '02X') +''+ format(255-probH, '02X') + '00'\n",
    "        try:\n",
    "            CVE = nodes[node]['CVE']\n",
    "            shape = nodes[node]['shape']\n",
    "            LABEL = nodes[node]['label']\n",
    "        except:\n",
    "            CVE = ''\n",
    "            shape = ''\n",
    "            LABEL = ''\n",
    "        color = 'lightblue' if node in dynamic_nodes else 'blue' if node in honeynodes else color\n",
    "        prob = \"{:.4f}\".format(prob)\n",
    "        if CVE != 'null':\n",
    "            return f'  \\\"{node}\\\" [label=\\\"{node}\\\\n{CVE}\\\\n{prob}\\\", color=\\\"{color}\\\", penwidth=3, shape=\\\"{shape}\\\"];\\n'\n",
    "        else:\n",
    "            rule = re.search(regex_rule, LABEL)\n",
    "            state = re.search(regex_state, LABEL)\n",
    "            if rule:\n",
    "                return f'  \\\"{node}\\\" [label=\\\"{node}\\\\n{rule.group(1)}\\\\n{prob}\\\", color=\\\"{color}\\\", penwidth=3, shape=\\\"{shape}\\\"];\\n'\n",
    "            elif state:\n",
    "                return f'  \\\"{node}\\\" [label=\\\"{node}\\\\n{state.group(1)}\\\\n{prob}\\\", color=\\\"{color}\\\", penwidth=3, shape=\\\"{shape}\\\"];\\n'\n",
    "            else:\n",
    "                return f'  \\\"{node}\\\" [label=\"{node}\\\\n{LABEL}\\\\n{prob}\", color=\"{color}\", penwidth=3, shape=\"{shape}\"];\\n'\n",
    "            \n",
    "    # Display the nodes\n",
    "    if display_kts:\n",
    "        for node in BAG.nodes():\n",
    "            dot += node_to_dot(node)\n",
    "    else:\n",
    "        for node in nodes.keys():\n",
    "            dot += node_to_dot(node)\n",
    "    # Display the edges \n",
    "    for edge in BAG.edges():\n",
    "        if display_kts or edge[0] in nodes.keys():\n",
    "            dot += f'  \\\"{edge[0]}\\\" -> \\\"{edge[1]}\\\";\\n'\n",
    "    dot += '}' # End of the dot file\n",
    "    # Write the dot file\n",
    "    with open(path / (basename + evidences_to_string(evidences) + \".dot\"), 'w') as f:\n",
    "        f.write(dot)\n",
    "\n",
    "def kts_layer(BAG, ONE, nodes):\n",
    "    with open('./Threat_Inteligence/kts_base_score.csv', mode='r') as kts_basescore_file:\n",
    "        reader = csv.DictReader(kts_basescore_file)\n",
    "        kts_base_score = {}\n",
    "        for row in reader:\n",
    "            kts_base_score[row['kts']] = float(row['base_score'])\n",
    "    # The skills layer:\n",
    "    cpd_Lskills = TabularCPD('Lskills', 2, [[1-kts_base_score['L']], [kts_base_score['L']]])\n",
    "    cpd_Hskills = TabularCPD('Hskills', 2, [[1-kts_base_score['H']], [kts_base_score['H']]])\n",
    "    \n",
    "    # The knowledge layer:\n",
    "    cpd_knowledge = [TabularCPD(knowledge, 2, [[0.3], [0.7]]) for knowledge in ['Known vulnerabilities', 'CQCM', 'No credentials', 'MITM', 'Permissions move', 'Privilege escalation', 'Lateral move', 'ADCS']]\n",
    "\n",
    "    # Import all the dependencies\n",
    "    cpt_l4 = create_AND_table([ONE, ONE, ONE, ONE])\n",
    "    with open('./Threat_Inteligence/CVE_knowledge_tooling_skills.csv', mode='r') as ktsfile:\n",
    "        reader = csv.DictReader(ktsfile)\n",
    "        kts_dict = {}\n",
    "        for row in reader:\n",
    "            cve = row['Vulnerability']\n",
    "            tmp = {'tool': row['tool'], 'skills': row['skills'], 'Type': row['Type']}\n",
    "            kts_dict[cve] = tmp\n",
    "    for node in nodes.items():\n",
    "            id = node[0]\n",
    "            node = node[1]\n",
    "            if node['CVE'] != \"null\":\n",
    "                row = kts_dict[node['CVE']]\n",
    "                tool_score = build_tools_tree(BAG, Parser(tokenizer(row['tool'])).parse(), id, ONE, kts_base_score)\n",
    "                skills_score = kts_base_score[row['skills']]\n",
    "                k_score = build_tools_tree(BAG, Parser(tokenizer(row['Type'])).parse(), id, ONE, kts_base_score)\n",
    "                # prob = kts_base_score[row['Type']] * kts_base_score[row['skills']] * kts_base_score[row['tool']]\n",
    "                prob = tool_score * skills_score * k_score\n",
    "                prob = prob + 0.01 - prob*0.01\n",
    "                cpt_l4 = [[1, 1-prob], [0, prob]]\n",
    "                parents = BAG.get_parents(id)\n",
    "                BAG.remove_cpds(id)\n",
    "                BAG.add_cpds(TabularCPD(id, 2, cpt_l4, parents, evidence_card=2*np.ones(len(parents))))\n",
    "    # We add all the necessary CPDs to the BAG\n",
    "    for cpd in [cpd_Lskills, cpd_Hskills] + cpd_knowledge:\n",
    "        if BAG.__contains__(cpd.variable):\n",
    "            BAG.add_cpds(cpd)\n",
    "\n",
    "def rmv_node(BAG, node):\n",
    "    edge = [(u,node) for u in BAG.get_parents(node)]\n",
    "    BAG.remove_edges_from(edge)\n",
    "    BAG.add_cpds(TabularCPD(node, 2, create_AND_table([0]).T))\n",
    "\n",
    "def evidences_to_string(evidences):\n",
    "    return ''.join([f'_{k}' for k, v in evidences.items()])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the folder containing the tree\n",
    "path = Path.cwd() / (\"Personnal_simulations/output_\" + simulation + \"/strongly_connected_components/\")\n",
    "file_name = \"ag-nocycles.dot\"\n",
    "path_to_dot = path / file_name\n",
    "basename = \"no_honey\"\n",
    "\n",
    "# We all read from the file, adding probabilities in the same time\n",
    "BAG, edges, nodes = parse_dot(open(path_to_dot, 'r').read(), ONE)\n",
    "\n",
    "# This is the reference BAG, before the attacker has compromised any node\n",
    "BAG_ref = BAG.copy()\n",
    "prop0 = BeliefPropagation(BAG_ref)\n",
    "\n",
    "# We create a dictionary to get the node number from the label\n",
    "inverted_nodes = {int(v['label'].split(':')[0]): k for k, v in nodes.items()}\n",
    "kts_layer(BAG, ONE, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 14 nodes and 14 edges\n"
     ]
    }
   ],
   "source": [
    "to_dot(BAG_ref, nodes, [], path, \"reference\", display_kts=False, calculate_probabilities=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 14 nodes and 14 edges\n",
      "BayesianNetwork with 14 nodes and 14 edges\n",
      "BayesianNetwork with 14 nodes and 14 edges\n",
      "BayesianNetwork with 14 nodes and 14 edges\n",
      "BayesianNetwork with 14 nodes and 14 edges\n",
      "+-------+-------+---------------------+\n",
      "| 11    | 11(0) | 11(1)               |\n",
      "+-------+-------+---------------------+\n",
      "| 10(0) | 1.0   | 0.9519839999999999  |\n",
      "+-------+-------+---------------------+\n",
      "| 10(1) | 0.0   | 0.04801600000000001 |\n",
      "+-------+-------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "evidences = [[], [9], [9, 7], [9, 7, 5], [9, 13, 5]]\n",
    "for evidence in evidences:\n",
    "    to_dot(BAG, nodes, evidence, path, basename, display_kts=False, calculate_probabilities=True)\n",
    "print(BAG.get_cpds('10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 39 nodes and 81 edges\n"
     ]
    }
   ],
   "source": [
    "evidence = []\n",
    "to_dot(BAG, nodes, evidence, path, basename, display_kts=False, calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 39 nodes and 81 edges\n",
      "BayesianNetwork with 39 nodes and 81 edges\n",
      "BayesianNetwork with 39 nodes and 81 edges\n"
     ]
    }
   ],
   "source": [
    "evidences = [[9,7], [9], [9, 7, 19]]\n",
    "for evidence in evidences:\n",
    "    to_dot(BAG, nodes, evidence, path, basename, display_kts=False, calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNetwork with 39 nodes and 81 edges\n",
      "BayesianNetwork with 39 nodes and 81 edges\n"
     ]
    }
   ],
   "source": [
    "evidences = [[9, 7, 19, 17], [9, 7, 19, 17, 15]]\n",
    "for evidence in evidences:\n",
    "    to_dot(BAG, nodes, evidence, path, basename, display_kts=False, calculate_probabilities=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
